# Repository Guidelines

## Project Structure & Module Organization
The `LiteDB/` library is the heart of the solution and is split into domains such as `Engine/`, `Document/`, `Client/`, and `Utils/` for low-level storage, document modeling, and public APIs. Companion apps live beside it: `LiteDB.Shell/` provides the interactive CLI, `LiteDB.Benchmarks/` and `LiteDB.Stress/` target performance and endurance scenarios, while `LiteDB.Tests/` houses unit coverage grouped by feature area. Sample integrations and temporary packaging output stay in `ConsoleApp1/` and `artifacts_temp/` respectively.

## Build, Test, and Development Commands
Restore and build with `dotnet build LiteDB.sln -c Release` after a `dotnet restore`. Execute `dotnet test LiteDB.sln --settings tests.runsettings` to honor the solution-wide timeout profile, or scope to a single project with `dotnet test LiteDB.Tests -f net8.0`. Launch the shell locally via `dotnet run --project LiteDB.Shell/LiteDB.Shell.csproj -- MyData.db`. Produce NuGet artifacts using `dotnet pack LiteDB/LiteDB.csproj -c Release` when preparing releases.

## Coding Style & Naming Conventions
Follow the repositoryâ€™s C# conventions: four-space indentation, Allman braces, and grouped `using` directives with system namespaces first. Prefer `var` only when the right-hand side is obvious, keep public APIs XML-documented (the build emits `LiteDB.xml`), and avoid introducing nullable warnings in both `netstandard2.0` and `net8.0` targets. Unsafe code is enabled; justify its use with comments tied to the relevant `Engine` component.

## Testing Guidelines
Tests are written with xUnit and FluentAssertions; mirror the production folder names (`Engine`, `Query`, `Issues`, etc.) when adding scenarios. Name files after the type under test and choose expressive `[Fact]` / `[Theory]` method names describing the behavior. Long-running tests must finish within the 300-second session timeout defined in `tests.runsettings`; run focused suites with `dotnet test LiteDB.Tests --filter FullyQualifiedName~Engine` to triage regressions quickly.

## Commit & Pull Request Guidelines
Commits use concise, present-tense subject lines (e.g., `Add test run settings`) and may reference issues inline (`Fix #123`). Each PR should describe the problem, the approach, and include before/after notes or perf metrics when touching storage internals. Link to tracking issues, attach shell transcripts or benchmarks where relevant, and confirm `dotnet test` output so reviewers can spot regressions.

## Versioning & Release Prep
Semantic versions are generated by MinVer; create annotated tags like `v6.0.0` on the main branch rather than editing project files manually. Before tagging, ensure Release builds are clean, pack outputs land in `artifacts_temp/`, and update any shell or benchmark usage notes affected by the change. Update this guide whenever you discover repository practices worth sharing.

